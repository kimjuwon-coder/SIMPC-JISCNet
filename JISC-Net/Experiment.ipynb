{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51215,
     "status": "ok",
     "timestamp": 1730869924781,
     "user": {
      "displayName": "주원",
      "userId": "12021316711199321178"
     },
     "user_tz": -540
    },
    "id": "z86RdSaAyP0y",
    "outputId": "83c42122-c2e0-425f-977f-1b0721336516"
   },
   "outputs": [],
   "source": [
    "!pip install python-weka-wrapper3\n",
    "!pip install fastdtw\n",
    "!pip install tslearn\n",
    "!pip install torch\n",
    "!pip install joblib\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install h5py\n",
    "!pip install dtaidistance\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1730869924781,
     "user": {
      "displayName": "주원",
      "userId": "12021316711199321178"
     },
     "user_tz": -540
    },
    "id": "ThK6r7bxpanF",
    "outputId": "806147ee-6656-4b13-e4a5-12e17670d579"
   },
   "outputs": [],
   "source": [
    "%cd /JISC-Net/jiscnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centroids shape:  (6, 22, 3)\n",
      "cluster_num:  6\n",
      "segmentation shape:  (566,)\n",
      "subsequence shape:  (566,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "variable = 'cvr' #c, v, r, cv, ...\n",
    "n_cluster = '6'\n",
    "init = 'trad' # kmpp, trad\n",
    "trad = '6' # init가 kmeans인 경우 빈 string\n",
    "\n",
    "if init == 'kmpp':\n",
    "    trad = ''\n",
    "\n",
    "base_path = '/SIMPC/res/BTC'\n",
    "file_name = f'simpc_{variable}_{n_cluster}_18_22_30_BTC_{trad}_k{n_cluster}_l18-22_dba_{init}' \n",
    "\n",
    "\n",
    "file_path = f'{base_path}/{file_name}_centroids.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    centroid = pickle.load(f)\n",
    "    print('centroids shape: ', centroid.shape) #centroids shape:  (6, 22, 3)\n",
    "    \n",
    "file_path = f'{base_path}/{file_name}_labels.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    labels = pickle.load(f)    #set {0, 1, 2, 3, 4, 5}\n",
    "    cluster_num = len(set(labels))\n",
    "    print('cluster_num: ', cluster_num)\n",
    "    \n",
    "file_path = f'{base_path}/{file_name}_segmentation.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    segmentation = pickle.load(f)\n",
    "    print('segmentation shape: ', segmentation.shape) # segmentation shape:  (467,) -> 시작점 index\n",
    "    \n",
    "file_path = f'{base_path}/{file_name}_subsequences.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    subsequences = pickle.load(f)\n",
    "    print('subsequence shape: ', subsequences.shape) # subsequence shape:  (467,) -> 다변량 시계열 subsequnce \n",
    "    #print(subsequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_instances 566\n",
      "num_variables 3\n",
      "Interpolated Data Shape: (566, 3, 100)\n"
     ]
    }
   ],
   "source": [
    "#보간 및 0-1 정규화 작업\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "def interpolate_normalize_subsequences(subsequences, target_length=100):\n",
    "    \"\"\"\n",
    "    모든 인스턴스(68개)와 변수(3개)에 대해 시계열을 target_length(100)으로 선형 보간.\n",
    "\n",
    "    :param subsequences: (68, 3, x) 형태의 리스트 (x는 가변 길이)\n",
    "    :param target_length: 보간 후 목표 길이 (기본값 100)\n",
    "    :return: (68, 3, 100) 형태의 numpy 배열\n",
    "    \"\"\"\n",
    "    num_instances = len(subsequences)  # 인스턴스 수 (68)\n",
    "    print('num_instances', num_instances)\n",
    "    num_variables = len(subsequences[0])  # 변수 수 (3)\n",
    "    print('num_variables',num_variables)\n",
    "\n",
    "    # 보간 후 저장할 배열\n",
    "    interpolated_data = np.zeros((num_instances, num_variables, target_length))\n",
    "\n",
    "    for i in range(num_instances):  # 각 인스턴스 반복\n",
    "        for j in range(num_variables):  # 각 변수 반복\n",
    "            series = np.array(subsequences[i][j])  # 현재 시계열 데이터 (x 길이)\n",
    "\n",
    "            # 기존 x 좌표 설정\n",
    "            original_length = len(series)\n",
    "            x_old = np.linspace(0, 1, original_length)  # 기존 데이터의 x 좌표\n",
    "            x_new = np.linspace(0, 1, target_length)  # 새로운 길이의 x 좌표\n",
    "\n",
    "            # 선형 보간 함수 적용\n",
    "            interpolator = interp1d(x_old, series, kind='linear')\n",
    "            interpolated_series = interpolator(x_new)\n",
    "\n",
    "            # 정규화 (Min-Max Scaling)\n",
    "            min_val = np.min(interpolated_series)\n",
    "            max_val = np.max(interpolated_series)\n",
    "            if max_val - min_val == 0:\n",
    "                normalized_series = np.zeros_like(interpolated_series)  # 값이 모두 같으면 0으로 채움\n",
    "            else:\n",
    "                normalized_series = (interpolated_series - min_val) / (max_val - min_val)\n",
    "\n",
    "            interpolated_data[i, j] = normalized_series\n",
    "    return interpolated_data\n",
    "\n",
    "\n",
    "target_length = 100  # 선형보간작업 얼마나 할건지 \n",
    "subsequences_list = [arr.T for arr in subsequences]\n",
    "interpolated_result = interpolate_normalize_subsequences(subsequences_list, target_length)\n",
    "print(\"Interpolated Data Shape:\", interpolated_result.shape)  # (68, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution:\n",
      " Label\n",
      "1    93\n",
      "0    85\n",
      "5    73\n",
      "3    69\n",
      "4    66\n",
      "2    66\n",
      "Name: count, dtype: int64\n",
      "Test label distribution:\n",
      " Label\n",
      "1    24\n",
      "0    21\n",
      "3    18\n",
      "5    18\n",
      "4    17\n",
      "2    16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#test/train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = {'Label': labels, 'Subsequence': pd.Series(interpolated_result.tolist())}\n",
    "df = pd.DataFrame(data)\n",
    "#print(df)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Label'])\n",
    "\n",
    "# 결과 확인\n",
    "print(\"Train label distribution:\\n\", train_df['Label'].value_counts(normalize=False))\n",
    "print(\"Test label distribution:\\n\", test_df['Label'].value_counts(normalize=False))\n",
    "\n",
    "train = np.array([row_i for row_i in train_df['Subsequence']])\n",
    "test = np.array([row_i for row_i in test_df['Subsequence']])\n",
    "train_labels = train_df['Label'].to_numpy()\n",
    "test_labels = test_df['Label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train: (452, 3, 100)\n",
      "Shape of train_labels: (452,)\n",
      "Shape of test: (114, 3, 100)\n",
      "Shape of test_labels: (114,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train:\", train.shape)\n",
    "print(\"Shape of train_labels:\", train_labels.shape)\n",
    "print(\"Shape of test:\", test.shape)\n",
    "print(\"Shape of test_labels:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import timeit\n",
    "import numpy as np\n",
    "import wrappers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# 명령행 인수 대신 직접 설정\n",
    "class Args:\n",
    "    save_path = '/JISC-Net/jiscnet/result/BTC_6_out64'     # 모델을 저장할 경로\n",
    "    hyper ='/JISC-Net/jiscnet/default_parameters.json'  # 하이퍼파라미터 파일 경로\n",
    "    load = False                # 모델을 로드할지 여부\n",
    "    fit_classifier = True      # 분류기를 학습할지 여부\n",
    "\n",
    "\n",
    "\n",
    "def fit_parameters(file, train, train_labels, test, test_labels, save_path, cluster_num,\n",
    "                        save_memory=False):\n",
    "    \"\"\"\n",
    "    Creates a classifier from the given set of parameters in the input\n",
    "    file, fits it and return it.\n",
    "\n",
    "    @param file Path of a file containing a set of hyperparemeters.\n",
    "    @param train Training set.\n",
    "    @param train_labels Labels for the training set.\n",
    "    @param cuda If True, enables computations on the GPU.\n",
    "    @param gpu GPU to use if CUDA is enabled.\n",
    "    @param save_memory If True, save GPU memory by propagating gradients after\n",
    "           each loss term, instead of doing it after computing the whole loss.\n",
    "    \"\"\"\n",
    "    classifier = wrappers.CausalCNNEncoderClassifier()\n",
    "\n",
    "    # Loads a given set of parameters and fits a model with those\n",
    "    hf = open(os.path.join(file), 'r')\n",
    "    params = json.load(hf)\n",
    "    hf.close()\n",
    "    print('params: ', params)\n",
    "    params['in_channels'] = train.shape[1]  #변수 갯수\n",
    "    classifier.set_params(**params)\n",
    "    return classifier.fit(\n",
    "        train, train_labels, test, test_labels, save_path, cluster_num, save_memory=save_memory, verbose=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = timeit.default_timer()\n",
    "    args = Args()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA is available, proceeding with it...\")\n",
    "    else:\n",
    "        print(\"CUDA is not available, proceeding without it...\")\n",
    "        args.cuda = False\n",
    "        \n",
    "\n",
    "    if not args.load and args.fit_classifier: #모델 학습, 분류기 학습 \n",
    "        classifier = fit_parameters(\n",
    "            args.hyper, train, train_labels, test, test_labels, args.save_path, cluster_num,\n",
    "            save_memory=False\n",
    "        )\n",
    "    else:\n",
    "        classifier = wrappers.CausalCNNEncoderClassifier()\n",
    "        hf = open('/JISC-Net/jiscnet/default_parameters.json', 'r')\n",
    "        hp_dict = json.load(hf)\n",
    "        hf.close()\n",
    "        classifier.set_params(**hp_dict)\n",
    "        classifier.load(os.path.join(args.save_path, args.dataset))\n",
    "\n",
    "\n",
    "    end = timeit.default_timer() \n",
    "    print(\"All time: \", (end- start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker 개수: 494\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "folder_path = \"/pic/STOCK\"\n",
    "ticker_set = set()\n",
    "\n",
    "# 정규표현식: plot_숫자_문자열_...\n",
    "pattern = re.compile(r\"plot_\\d+_([A-Z]+)_\")\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    match = pattern.match(filename)\n",
    "    if match:\n",
    "        ticker = match.group(1)\n",
    "        ticker_set.add(ticker)\n",
    "\n",
    "print(f\"Ticker 개수: {len(ticker_set)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "shapenet",
   "language": "python",
   "name": "shapenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
